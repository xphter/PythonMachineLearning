import DeviceConfig;
DeviceConfig.floatLength = 32;

from TS2Vec import *;
from TS2Vec import _TemporalContrastiveLoss, _InstanceContrastiveLoss, _ContrastiveLoss, _ConvolutionBlock, _Encoder;

import pickle;
import random;
from datetime import datetime;

import torch;
import torch.nn as nn;
import torch.nn.functional as F;
from torch.utils.data import TensorDataset, DataLoader;


def getErrorText(title : str, x1 : np.ndarray, x2 : np.ndarray) -> str:
    return f", {title}: {np.sum(np.fabs(x1 - x2))}({np.linalg.norm(x1 - x2) / (np.linalg.norm(x1) + np.linalg.norm(x2))})";


def injectTorchParams(m1 : nn.Module, m2 : INetModule):
    for p1, p2 in zip(list(m1.parameters()), m2.params):
        p1Value = p1.data.detach().numpy();
        p2.value[...] = p1Value if p1Value.shape == p2.value.shape else p1Value.T;
    m2.params = m2.params;


def testTorchTensors(tensors : List[torch.Tensor], arrays : List[np.ndarray]):
    for p1, p2 in zip(tensors, arrays):
        p1Value = p1.detach().numpy(); # type: ignore
        print(getErrorText("", p1Value if p1Value.shape == p2.shape else p1Value.T, p2));


def testTorchParams(m1 : nn.Module, m2 : INetModule):
    for p1, p2 in zip(list(m1.parameters()), m2.params):
        p1Value = p1.data.detach().numpy(); # type: ignore
        print(getErrorText(p2.name, p1Value if p1Value.shape == p2.value.shape else p1Value.T, p2.value));


def testTorchGradients(m1 : nn.Module, m2 : INetModule):
    for p1, p2 in zip(list(m1.parameters()), m2.params):
        p1Grad = p1.grad.detach().numpy(); # type: ignore
        print(getErrorText(p2.name, p1Grad if p1Grad.shape == p2.grad.shape else p1Grad.T, p2.grad));


def sumAll(*X : np.ndarray) -> float:
    return sum([float(np.sum(x)) for x in X]);


def testModuleGradient(m : INetModule, title: str, *data : np.ndarray):
    numGradients = [];

    for p in m.params:
        v = p.value;
        numGradients.append(numericGradient(lambda x : sumAll(*m.copy(True).forward(*data)), v));

    message = '\n'.join([f'param {m.params[i].name}{i}{m.params[i].value.shape} error value: {np.sum(np.fabs(m.params[i].grad - numGradients[i]))}, error ratio: {np.linalg.norm(m.params[i].grad - numGradients[i]) / (np.linalg.norm(m.params[i].grad) + np.linalg.norm(numGradients[i]))}' for i in range(len(m.params))]);
    print(f"{title}\n{message}");


def temporal_contrastive_loss(z1, z2):
    B, T = z1.size(0), z1.size(1)
    if T == 1:
        return z1.new_tensor(0.)
    z = torch.cat([z1, z2], dim=1)  # B x 2T x C
    sim = torch.matmul(z, z.transpose(1, 2))  # B x 2T x 2T
    logits = torch.tril(sim, diagonal=-1)[:, :, :-1]    # B x 2T x (2T-1)
    logits += torch.triu(sim, diagonal=1)[:, :, 1:]
    logits = -F.log_softmax(logits, dim=-1)
    
    t = torch.arange(T, device=z1.device)
    loss = (logits[:, t, T + t - 1].mean() + logits[:, T + t, t].mean()) / 2
    return loss


def instance_contrastive_loss(z1, z2):
    B, T = z1.size(0), z1.size(1)
    if B == 1:
        return z1.new_tensor(0.)
    z = torch.cat([z1, z2], dim=0)  # 2B x T x C
    z = z.transpose(0, 1)  # T x 2B x C
    sim = torch.matmul(z, z.transpose(1, 2))  # T x 2B x 2B
    logits = torch.tril(sim, diagonal=-1)[:, :, :-1]    # T x 2B x (2B-1)
    logits += torch.triu(sim, diagonal=1)[:, :, 1:]
    logits = -F.log_softmax(logits, dim=-1)
    
    i = torch.arange(B, device=z1.device)
    loss = (logits[:, i, B + i - 1].mean() + logits[:, B + i, i].mean()) / 2
    return loss


def hierarchical_contrastive_loss(z1, z2, alpha=0.5, temporal_unit=0):
    loss = torch.tensor(0., device=z1.device)
    d = 0
    while z1.size(1) > 1:
        if alpha != 0:
            loss += alpha * instance_contrastive_loss(z1, z2)
        if d >= temporal_unit:
            if 1 - alpha != 0:
                loss += (1 - alpha) * temporal_contrastive_loss(z1, z2)
        d += 1
        z1 = F.max_pool1d(z1.transpose(1, 2), kernel_size=2).transpose(1, 2)
        z2 = F.max_pool1d(z2.transpose(1, 2), kernel_size=2).transpose(1, 2)
    if z1.size(1) == 1:
        if alpha != 0:
            loss += alpha * instance_contrastive_loss(z1, z2)
        d += 1
    return loss / d


class SamePadConv(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, groups=1):
        super().__init__()
        self.receptive_field = (kernel_size - 1) * dilation + 1
        padding = self.receptive_field // 2
        self.conv = nn.Conv1d(
            in_channels, out_channels, kernel_size,
            padding=padding,
            dilation=dilation,
            groups=groups
        )
        self.remove = 1 if self.receptive_field % 2 == 0 else 0
        
    def forward(self, x):
        out = self.conv(x)
        if self.remove > 0:
            out = out[:, :, : -self.remove]
        return out


class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, dilation, final=False):
        super().__init__()
        self.conv1 = SamePadConv(in_channels, out_channels, kernel_size, dilation=dilation)
        self.conv2 = SamePadConv(out_channels, out_channels, kernel_size, dilation=dilation)
        self.projector = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels or final else None
    
    def forward(self, x):
        residual = x if self.projector is None else self.projector(x)
        x = F.gelu(x)
        x = self.conv1(x)
        x = F.gelu(x)
        x = self.conv2(x)
        return x + residual


class DilatedConvEncoder(nn.Module):
    def __init__(self, in_channels, channels, kernel_size):
        super().__init__()
        self.net = nn.Sequential(*[
            ConvBlock(
                channels[i-1] if i > 0 else in_channels,
                channels[i],
                kernel_size=kernel_size,
                dilation=2**i,
                final=(i == len(channels)-1)
            )
            for i in range(len(channels))
        ])
        
    def forward(self, x):
        return self.net(x)


def generate_continuous_mask(B, T, n=5, l=0.1):
    res = torch.full((B, T), True, dtype=torch.bool)
    if isinstance(n, float):
        n = int(n * T)
    n = max(min(n, T // 2), 1)
    
    if isinstance(l, float):
        l = int(l * T)
    l = max(l, 1)
    
    for i in range(B):
        for _ in range(n):
            t = np.random.randint(T-l+1)
            res[i, t:t+l] = False
    return res


def generate_binomial_mask(B, T, p=0.5):
    return torch.from_numpy(np.random.binomial(1, p, size=(B, T))).to(torch.bool)


class TSEncoder(nn.Module):
    def __init__(self, input_dims, output_dims, hidden_dims=64, depth=10, mask_mode='binomial', dropout=0.1):
        super().__init__()
        self.input_dims = input_dims
        self.output_dims = output_dims
        self.hidden_dims = hidden_dims
        self.mask_mode = mask_mode
        self.input_fc = nn.Linear(input_dims, hidden_dims)
        self.feature_extractor = DilatedConvEncoder(
            hidden_dims,
            [hidden_dims] * depth + [output_dims],
            kernel_size=3
        )
        self.repr_dropout = nn.Dropout(p=dropout)
        
    def forward(self, x, mask=None):  # x: B x T x input_dims
        nan_mask = ~x.isnan().any(axis=-1)
        x[~nan_mask] = 0
        x = self.input_fc(x)  # B x T x Ch
        
        # generate & apply mask
        if mask is None:
            if self.training:
                mask = self.mask_mode
            else:
                mask = 'all_true'
        
        if mask == 'binomial':
            mask = generate_binomial_mask(x.size(0), x.size(1)).to(x.device)
        elif mask == 'continuous':
            mask = generate_continuous_mask(x.size(0), x.size(1)).to(x.device)
        elif mask == 'all_true':
            mask = x.new_full((x.size(0), x.size(1)), True, dtype=torch.bool)
        elif mask == 'all_false':
            mask = x.new_full((x.size(0), x.size(1)), False, dtype=torch.bool)
        elif mask == 'mask_last':
            mask = x.new_full((x.size(0), x.size(1)), True, dtype=torch.bool)
            mask[:, -1] = False
        
        mask &= nan_mask
        x[~mask] = 0
        
        # conv encoder
        x = x.transpose(1, 2)  # B x Ch x T
        x = self.repr_dropout(self.feature_extractor(x))  # B x Co x T
        x = x.transpose(1, 2)  # B x T x Co
        
        return x


# region utils.py


def pkl_save(name, var):
    with open(name, 'wb') as f:
        pickle.dump(var, f)

def pkl_load(name):
    with open(name, 'rb') as f:
        return pickle.load(f)
    
def torch_pad_nan(arr, left=0, right=0, dim=0):
    if left > 0:
        padshape = list(arr.shape)
        padshape[dim] = left
        arr = torch.cat((torch.full(padshape, np.nan), arr), dim=dim)
    if right > 0:
        padshape = list(arr.shape)
        padshape[dim] = right
        arr = torch.cat((arr, torch.full(padshape, np.nan)), dim=dim)
    return arr
    
def pad_nan_to_target(array, target_length, axis=0, both_side=False):
    assert array.dtype in [np.float16, np.float32, np.float64]
    pad_size = target_length - array.shape[axis]
    if pad_size <= 0:
        return array
    npad = [(0, 0)] * array.ndim
    if both_side:
        npad[axis] = (pad_size // 2, pad_size - pad_size//2)
    else:
        npad[axis] = (0, pad_size)
    return np.pad(array, pad_width=npad, mode='constant', constant_values=np.nan)

def split_with_nan(x, sections, axis=0):
    assert x.dtype in [np.float16, np.float32, np.float64]
    arrs = np.array_split(x, sections, axis=axis)
    target_length = arrs[0].shape[axis]
    for i in range(len(arrs)):
        arrs[i] = pad_nan_to_target(arrs[i], target_length, axis=axis)
    return arrs

def take_per_row(A, indx, num_elem):
    all_indx = indx[:,None] + np.arange(num_elem)
    return A[torch.arange(all_indx.shape[0])[:,None], all_indx]

def centerize_vary_length_series(x):
    prefix_zeros = np.argmax(~np.isnan(x).all(axis=-1), axis=1)
    suffix_zeros = np.argmax(~np.isnan(x[:, ::-1]).all(axis=-1), axis=1)
    offset = (prefix_zeros + suffix_zeros) // 2 - prefix_zeros
    rows, column_indices = np.ogrid[:x.shape[0], :x.shape[1]]
    offset[offset < 0] += x.shape[1]
    column_indices = column_indices - offset[:, np.newaxis]
    return x[rows, column_indices]

def data_dropout(arr, p):
    B, T = arr.shape[0], arr.shape[1]
    mask = np.full(B*T, False, dtype=np.bool)
    ele_sel = np.random.choice(
        B*T,
        size=int(B*T*p),
        replace=False
    )
    mask[ele_sel] = True
    res = arr.copy()
    res[mask.reshape(B, T)] = np.nan
    return res

def name_with_datetime(prefix='default'):
    now = datetime.now()
    return prefix + '_' + now.strftime("%Y%m%d_%H%M%S")

def init_dl_program(
    device_name,
    seed=None,
    use_cudnn=True,
    deterministic=False,
    benchmark=False,
    use_tf32=False,
    max_threads=None
):
    import torch
    if max_threads is not None:
        torch.set_num_threads(max_threads)  # intraop
        if torch.get_num_interop_threads() != max_threads:
            torch.set_num_interop_threads(max_threads)  # interop
        try:
            import mkl
        except:
            pass
        else:
            mkl.set_num_threads(max_threads)
        
    if seed is not None:
        random.seed(seed)
        seed += 1
        np.random.seed(seed)
        seed += 1
        torch.manual_seed(seed)
        
    if isinstance(device_name, (str, int)):
        device_name = [device_name]
    
    devices = []
    for t in reversed(device_name):
        t_device = torch.device(t)
        devices.append(t_device)
        if t_device.type == 'cuda':
            assert torch.cuda.is_available()
            torch.cuda.set_device(t_device)
            if seed is not None:
                seed += 1
                torch.cuda.manual_seed(seed)
    devices.reverse()
    torch.backends.cudnn.enabled = use_cudnn
    torch.backends.cudnn.deterministic = deterministic
    torch.backends.cudnn.benchmark = benchmark
    
    if hasattr(torch.backends.cudnn, 'allow_tf32'):
        torch.backends.cudnn.allow_tf32 = use_tf32
        torch.backends.cuda.matmul.allow_tf32 = use_tf32
        
    return devices if len(devices) > 1 else devices[0]


# endregion

class TS2Vec:
    '''The TS2Vec model'''
    
    def __init__(
        self,
        input_dims,
        output_dims=320,
        hidden_dims=64,
        depth=10,
        device='cuda',
        lr=0.001,
        batch_size=16,
        max_train_length=None,
        temporal_unit=0,
        after_iter_callback=None,
        after_epoch_callback=None
    ):
        ''' Initialize a TS2Vec model.
        
        Args:
            input_dims (int): The input dimension. For a univariate time series, this should be set to 1.
            output_dims (int): The representation dimension.
            hidden_dims (int): The hidden dimension of the encoder.
            depth (int): The number of hidden residual blocks in the encoder.
            device (int): The gpu used for training and inference.
            lr (int): The learning rate.
            batch_size (int): The batch size.
            max_train_length (Union[int, NoneType]): The maximum allowed sequence length for training. For sequence with a length greater than <max_train_length>, it would be cropped into some sequences, each of which has a length less than <max_train_length>.
            temporal_unit (int): The minimum unit to perform temporal contrast. When training on a very long sequence, this param helps to reduce the cost of time and memory.
            after_iter_callback (Union[Callable, NoneType]): A callback function that would be called after each iteration.
            after_epoch_callback (Union[Callable, NoneType]): A callback function that would be called after each epoch.
        '''
        
        super().__init__()
        self.device = device
        self.lr = lr
        self.batch_size = batch_size
        self.max_train_length = max_train_length
        self.temporal_unit = temporal_unit
        
        self._net = TSEncoder(input_dims=input_dims, output_dims=output_dims, hidden_dims=hidden_dims, depth=depth, dropout=0.0).to(self.device)
        self.net = torch.optim.swa_utils.AveragedModel(self._net)
        self.net.update_parameters(self._net)
        
        self.after_iter_callback = after_iter_callback
        self.after_epoch_callback = after_epoch_callback
        
        self.n_epochs = 0
        self.n_iters = 0
    
    def fit(self, train_data, n_epochs=None, n_iters=None, verbose=False):
        ''' Training the TS2Vec model.
        
        Args:
            train_data (numpy.ndarray): The training data. It should have a shape of (n_instance, n_timestamps, n_features). All missing data should be set to NaN.
            n_epochs (Union[int, NoneType]): The number of epochs. When this reaches, the training stops.
            n_iters (Union[int, NoneType]): The number of iterations. When this reaches, the training stops. If both n_epochs and n_iters are not specified, a default setting would be used that sets n_iters to 200 for a dataset with size <= 100000, 600 otherwise.
            verbose (bool): Whether to print the training loss after each epoch.
            
        Returns:
            loss_log: a list containing the training losses on each epoch.
        '''
        assert train_data.ndim == 3
        
        if n_iters is None and n_epochs is None:
            n_iters = 200 if train_data.size <= 100000 else 600  # default param for n_iters
        
        if self.max_train_length is not None:
            sections = train_data.shape[1] // self.max_train_length
            if sections >= 2:
                train_data = np.concatenate(split_with_nan(train_data, sections, axis=1), axis=0)

        temporal_missing = np.isnan(train_data).all(axis=-1).any(axis=0)
        if temporal_missing[0] or temporal_missing[-1]:
            train_data = centerize_vary_length_series(train_data)
                
        train_data = train_data[~np.isnan(train_data).all(axis=2).all(axis=1)]
        
        train_dataset = TensorDataset(torch.from_numpy(train_data).to(torch.float))
        train_loader = DataLoader(train_dataset, batch_size=min(self.batch_size, len(train_dataset)), shuffle=False, drop_last=False)
        
        # optimizer = torch.optim.AdamW(self._net.parameters(), lr=self.lr)
        optimizer = torch.optim.SGD(self._net.parameters(), lr=self.lr)
        
        loss_log, z_log = [], [];
        
        while True:
            if n_epochs is not None and self.n_epochs >= n_epochs:
                break
            
            cum_loss = 0
            n_epoch_iters = 0
            
            interrupted = False
            for batch in train_loader:
                if n_iters is not None and self.n_iters >= n_iters:
                    interrupted = True
                    break
                
                x = batch[0]
                if self.max_train_length is not None and x.size(1) > self.max_train_length:
                    window_offset = np.random.randint(x.size(1) - self.max_train_length + 1)
                    x = x[:, window_offset : window_offset + self.max_train_length]
                x = x.to(self.device)
                
                ts_l = x.size(1)
                crop_l = np.random.randint(low=2 ** (self.temporal_unit + 1), high=ts_l+1)
                crop_left = np.random.randint(ts_l - crop_l + 1)
                crop_right = crop_left + crop_l
                crop_eleft = np.random.randint(crop_left + 1)
                crop_eright = np.random.randint(low=crop_right, high=ts_l + 1)
                crop_offset = np.random.randint(low=-crop_eleft, high=ts_l - crop_eright + 1, size=x.size(0))
                
                optimizer.zero_grad()
                
                out1 = self._net(take_per_row(x, crop_offset + crop_eleft, crop_right - crop_eleft))
                out1 = out1[:, -crop_l:]
                
                out2 = self._net(take_per_row(x, crop_offset + crop_left, crop_eright - crop_left))
                out2 = out2[:, :crop_l]

                z_log.append((out1.detach().numpy(), out2.detach().numpy()));
                
                loss = hierarchical_contrastive_loss(
                    out1,
                    out2,
                    temporal_unit=self.temporal_unit
                )
                
                loss.backward()
                optimizer.step()
                self.net.update_parameters(self._net)
                    
                cum_loss += loss.item()
                n_epoch_iters += 1
                
                self.n_iters += 1
                
                if self.after_iter_callback is not None:
                    self.after_iter_callback(self, loss.item())
            
            if interrupted:
                break
            
            cum_loss /= n_epoch_iters
            loss_log.append(cum_loss)
            if verbose:
                print(f"Epoch #{self.n_epochs}: loss={cum_loss}")
            self.n_epochs += 1
            
            if self.after_epoch_callback is not None:
                self.after_epoch_callback(self, cum_loss)
            
        return loss_log, z_log;
    
    def _eval_with_pooling(self, x, mask=None, slicing=None, encoding_window=None):
        out = self.net(x.to(self.device, non_blocking=True), mask)
        if encoding_window == 'full_series':
            if slicing is not None:
                out = out[:, slicing]
            out = F.max_pool1d(
                out.transpose(1, 2),
                kernel_size = out.size(1),
            ).transpose(1, 2)
            
        elif isinstance(encoding_window, int):
            out = F.max_pool1d(
                out.transpose(1, 2),
                kernel_size = encoding_window,
                stride = 1,
                padding = encoding_window // 2
            ).transpose(1, 2)
            if encoding_window % 2 == 0:
                out = out[:, :-1]
            if slicing is not None:
                out = out[:, slicing]
            
        elif encoding_window == 'multiscale':
            p = 0
            reprs = []
            while (1 << p) + 1 < out.size(1):
                t_out = F.max_pool1d(
                    out.transpose(1, 2),
                    kernel_size = (1 << (p + 1)) + 1,
                    stride = 1,
                    padding = 1 << p
                ).transpose(1, 2)
                if slicing is not None:
                    t_out = t_out[:, slicing]
                reprs.append(t_out)
                p += 1
            out = torch.cat(reprs, dim=-1)
            
        else:
            if slicing is not None:
                out = out[:, slicing]
            
        return out.cpu()
    
    def encode(self, data, mask=None, encoding_window=None, causal=False, sliding_length=None, sliding_padding=0, batch_size=None):
        ''' Compute representations using the model.
        
        Args:
            data (numpy.ndarray): This should have a shape of (n_instance, n_timestamps, n_features). All missing data should be set to NaN.
            mask (str): The mask used by encoder can be specified with this parameter. This can be set to 'binomial', 'continuous', 'all_true', 'all_false' or 'mask_last'.
            encoding_window (Union[str, int]): When this param is specified, the computed representation would the max pooling over this window. This can be set to 'full_series', 'multiscale' or an integer specifying the pooling kernel size.
            causal (bool): When this param is set to True, the future informations would not be encoded into representation of each timestamp.
            sliding_length (Union[int, NoneType]): The length of sliding window. When this param is specified, a sliding inference would be applied on the time series.
            sliding_padding (int): This param specifies the contextual data length used for inference every sliding windows.
            batch_size (Union[int, NoneType]): The batch size used for inference. If not specified, this would be the same batch size as training.
            
        Returns:
            repr: The representations for data.
        '''
        assert self.net is not None, 'please train or load a net first'
        assert data.ndim == 3
        if batch_size is None:
            batch_size = self.batch_size
        n_samples, ts_l, _ = data.shape

        org_training = self.net.training
        self.net.eval()
        
        dataset = TensorDataset(torch.from_numpy(data).to(torch.float))
        loader = DataLoader(dataset, batch_size=batch_size)
        
        with torch.no_grad():
            output = []
            for batch in loader:
                x = batch[0]
                if sliding_length is not None:
                    reprs = []
                    if n_samples < batch_size:
                        calc_buffer = []
                        calc_buffer_l = 0
                    for i in range(0, ts_l, sliding_length):
                        l = i - sliding_padding
                        r = i + sliding_length + (sliding_padding if not causal else 0)
                        x_sliding = torch_pad_nan(
                            x[:, max(l, 0) : min(r, ts_l)],
                            left=-l if l<0 else 0,
                            right=r-ts_l if r>ts_l else 0,
                            dim=1
                        )
                        if n_samples < batch_size:
                            if calc_buffer_l + n_samples > batch_size:
                                out = self._eval_with_pooling(
                                    torch.cat(calc_buffer, dim=0),
                                    mask,
                                    slicing=slice(sliding_padding, sliding_padding+sliding_length),
                                    encoding_window=encoding_window
                                )
                                reprs += torch.split(out, n_samples)
                                calc_buffer = []
                                calc_buffer_l = 0
                            calc_buffer.append(x_sliding)
                            calc_buffer_l += n_samples
                        else:
                            out = self._eval_with_pooling(
                                x_sliding,
                                mask,
                                slicing=slice(sliding_padding, sliding_padding+sliding_length),
                                encoding_window=encoding_window
                            )
                            reprs.append(out)

                    if n_samples < batch_size:
                        if calc_buffer_l > 0:
                            out = self._eval_with_pooling(
                                torch.cat(calc_buffer, dim=0),
                                mask,
                                slicing=slice(sliding_padding, sliding_padding+sliding_length),
                                encoding_window=encoding_window
                            )
                            reprs += torch.split(out, n_samples)
                            calc_buffer = []
                            calc_buffer_l = 0
                    
                    out = torch.cat(reprs, dim=1)
                    if encoding_window == 'full_series':
                        out = F.max_pool1d(
                            out.transpose(1, 2).contiguous(),
                            kernel_size = out.size(1),
                        ).squeeze(1)
                else:
                    out = self._eval_with_pooling(x, mask, encoding_window=encoding_window)
                    if encoding_window == 'full_series':
                        out = out.squeeze(1)
                        
                output.append(out)
                
            output = torch.cat(output, dim=0)
            
        self.net.train(org_training)
        return output.numpy()
    
    def save(self, fn):
        ''' Save the model to a file.
        
        Args:
            fn (str): filename.
        '''
        torch.save(self.net.state_dict(), fn)
    
    def load(self, fn):
        ''' Load the model from a file.
        
        Args:
            fn (str): filename.
        '''
        state_dict = torch.load(fn, map_location=self.device)
        self.net.load_state_dict(state_dict)
    

def testTemporalContrastiveLoss1():
    batchSize, timeStep, latentSize = 32, 12, 8;
    Z1 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);

    m = _TemporalContrastiveLoss();
    y1 = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward(defaultDType(1));

    Z3, Z4 = torch.tensor(Z1, requires_grad = True), torch.tensor(Z2, requires_grad = True);
    y2 = temporal_contrastive_loss(Z3, Z4);
    y2.backward();
    y2 = y2.detach().numpy();
    dZ3, dZ4 = Z3.grad.detach().numpy(), Z4.grad.detach().numpy(); # type: ignore
    print(f"_TemporalContrastiveLoss, value1, y error: {np.fabs(y1 - y2)} {getErrorText('dZ1 error', dZ1, dZ3)} {getErrorText('dZ2 error', dZ2, dZ4)}");
    print("\n");


def testTemporalContrastiveLossGradient1():
    batchSize, timeStep, latentSize = 32, 12, 8;
    Z1 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);

    m = _TemporalContrastiveLoss();
    y = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward(defaultDType(1.0));
    dZ1N = numericGradient(lambda x: m.forward(x, Z2), Z1);
    dZ2N = numericGradient(lambda x: m.forward(Z1, x), Z2);
    print(f"_TemporalContrastiveLoss, numericGradient1 {getErrorText('dZ1 error', dZ1, dZ1N)} {getErrorText('dZ2 error', dZ2, dZ2N)}");
    print("\n");


def testTemporalContrastiveLossGradient2():
    sequenceNum, batchSize, timeStep, latentSize = 3, 32, 12, 8;
    Z1 = np.random.randn(sequenceNum, batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(sequenceNum, batchSize, timeStep, latentSize).astype(defaultDType);

    m = _TemporalContrastiveLoss();
    y = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward(defaultDType(1.0));
    dZ1N = numericGradient(lambda x: m.forward(x, Z2), Z1);
    dZ2N = numericGradient(lambda x: m.forward(Z1, x), Z2);
    print(f"_TemporalContrastiveLoss, numericGradient2 {getErrorText('dZ1 error', dZ1, dZ1N)} {getErrorText('dZ2 error', dZ2, dZ2N)}");
    print("\n");


def testInstanceContrastiveLoss1():
    batchSize, timeStep, latentSize = 32, 12, 8;
    Z1 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);

    m = _InstanceContrastiveLoss();
    y1 = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward(defaultDType(1));

    Z3, Z4 = torch.tensor(Z1, requires_grad = True), torch.tensor(Z2, requires_grad = True);
    y2 = instance_contrastive_loss(Z3, Z4);
    y2.backward();
    y2 = y2.detach().numpy();
    dZ3, dZ4 = Z3.grad.detach().numpy(), Z4.grad.detach().numpy(); # type: ignore
    print(f"_InstanceContrastiveLoss, value1, y error: {np.fabs(y1 - y2)} {getErrorText('dZ1 error', dZ1, dZ3)} {getErrorText('dZ2 error', dZ2, dZ4)}");
    print("\n");


def testContrastiveLossGradient1():
    batchSize, timeStep, latentSize = 32, 12, 8;
    Z1 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);

    m = _ContrastiveLoss(0.7);
    y = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward(defaultDType(1.0));
    dZ1N = numericGradient(lambda x: m.forward(x, Z2), Z1);
    dZ2N = numericGradient(lambda x: m.forward(Z1, x), Z2);
    print(f"_ContrastiveLoss, numericGradient1 {getErrorText('dZ1 error', dZ1, dZ1N)} {getErrorText('dZ2 error', dZ2, dZ2N)}");
    print("\n");


def testContrastiveLossGradient2():
    batchSize, timeStep, latentSize = 32, 12, 8;
    Z1 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);

    m = _ContrastiveLoss(0.7, 0.0);
    y = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward(defaultDType(1.0));
    dZ1N = numericGradient(lambda x: m.forward(x, Z2), Z1);
    dZ2N = numericGradient(lambda x: m.forward(Z1, x), Z2);
    print(f"_ContrastiveLoss, numericGradient2 {getErrorText('dZ1 error', dZ1, dZ1N)} {getErrorText('dZ2 error', dZ2, dZ2N)}");
    print("\n");


def testContrastiveLossGradient3():
    batchSize, timeStep, latentSize = 32, 12, 8;
    Z1 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);

    m = _ContrastiveLoss(0., 0.7);
    y = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward(defaultDType(1.0));
    dZ1N = numericGradient(lambda x: m.forward(x, Z2), Z1);
    dZ2N = numericGradient(lambda x: m.forward(Z1, x), Z2);
    print(f"_ContrastiveLoss, numericGradient3 {getErrorText('dZ1 error', dZ1, dZ1N)} {getErrorText('dZ2 error', dZ2, dZ2N)}");
    print("\n");


def testTS2VecLossValue1(instanceLossWeight : float, minTemporalUnit : int = 0):
    batchSize, timeStep, latentSize = 32, 12, 8;
    Z1 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);

    m = TS2VecLoss(instanceLossWeight = instanceLossWeight, minTemporalUnit = minTemporalUnit);
    loss1 = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward();

    Z3, Z4 = torch.tensor(Z1, requires_grad = True), torch.tensor(Z2, requires_grad = True);
    loss2 = hierarchical_contrastive_loss(Z3, Z4, alpha = instanceLossWeight, temporal_unit = minTemporalUnit);
    loss2.backward();
    loss2 = loss2.detach().numpy();
    dZ3, dZ4 = Z3.grad.detach().numpy(), Z4.grad.detach().numpy(); # type: ignore
    print(f"TS2VecLoss, value1, instanceLossWeight: {instanceLossWeight}, minTemporalUnit: {minTemporalUnit}, loss error: {np.fabs(loss1 - loss2)} {getErrorText('dZ1 error', dZ1, dZ3)} {getErrorText('dZ2 error', dZ2, dZ4)}");
    print("\n");


def testTS2VecLossGradient1():
    batchSize, timeStep, latentSize = 32, 12, 8;
    Z1 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);
    Z2 = np.random.randn(batchSize, timeStep, latentSize).astype(defaultDType);

    m = TS2VecLoss(0.7);
    loss = m.forward(Z1, Z2);
    dZ1, dZ2 = m.backward();
    dZ1N = numericGradient(lambda x: m.forward(x, Z2), Z1);
    dZ2N = numericGradient(lambda x: m.forward(Z1, x), Z2);
    print(f"TS2VecLoss, numericGradient1 {getErrorText('dZ1 error', dZ1, dZ1N)} {getErrorText('dZ2 error', dZ2, dZ2N)}");
    print("\n");


def testConvolutionBlock1():
    batchSize, sequenceLength = 32, 24;
    inputChannel, outputChannel, kernelSize, dilation = 7, 7, 3, 2;
    X = np.random.randn(batchSize, inputChannel, sequenceLength).astype(defaultDType);

    X1 = torch.tensor(X, dtype = torch.float32, requires_grad = True);
    block1 = ConvBlock(inputChannel, outputChannel, kernelSize, dilation);
    Y1 = block1(X1);
    torch.sum(Y1).backward();
    Y1 = Y1.detach().numpy();
    dX1 = X1.grad.detach().numpy(); # type: ignore

    X2 = X;
    block2 = _ConvolutionBlock(inputChannel, outputChannel, kernelSize, dilation);
    injectTorchParams(block1, block2);
    Y2, = block2.forward(X2);
    dX2, = block2.backward(np.ones_like(Y2));

    print(f"_ConvolutionBlock, value1 {getErrorText('Y error', Y1, Y2)} {getErrorText('dX error', dX1, dX2)}");
    testTorchGradients(block1, block2);

    print("\n");


def testConvolutionBlock2():
    batchSize, sequenceLength = 32, 24;
    inputChannel, outputChannel, kernelSize, dilation = 7, 8, 3, 2;
    X = np.random.randn(batchSize, inputChannel, sequenceLength).astype(defaultDType);

    X1 = torch.tensor(X, dtype = torch.float32, requires_grad = True);
    block1 = ConvBlock(inputChannel, outputChannel, kernelSize, dilation);
    Y1 = block1(X1);
    torch.sum(Y1).backward();
    Y1 = Y1.detach().numpy();
    dX1 = X1.grad.detach().numpy(); # type: ignore

    X2 = X;
    block2 = _ConvolutionBlock(inputChannel, outputChannel, kernelSize, dilation);
    injectTorchParams(block1, block2);
    Y2, = block2.forward(X2);
    dX2, = block2.backward(np.ones_like(Y2));

    print(f"_ConvolutionBlock, value2 {getErrorText('Y error', Y1, Y2)} {getErrorText('dX error', dX1, dX2)}");
    testTorchGradients(block1, block2);

    print("\n");


def testConvolutionBlockGradient1():
    batchSize, sequenceLength = 32, 24;
    inputChannel, outputChannel, kernelSize, dilation = 7, 8, 3, 2;
    X = np.random.randn(batchSize, inputChannel, sequenceLength).astype(defaultDType);

    m = _ConvolutionBlock(inputChannel, outputChannel, kernelSize, dilation);
    Y, = m.forward(X);
    dX1, = m.backward(np.ones_like(Y));
    dX1N = numericGradient(lambda x: np.sum(m.forward(x)[0]), X);
    print(f"_ConvolutionBlock, numericGradient1 {getErrorText('dX error', dX1, dX1N)}");
    testModuleGradient(m, "_ConvolutionBlock, numericGradient1", X);
    print("\n");


def testConvolutionBlockGradient2():
    batchSize, sequenceLength = 32, 24;
    inputChannel, outputChannel1, outputChannel2, outputChannel3, kernelSize = 7, 7, 8, 8, 3;
    X = np.random.randn(batchSize, inputChannel, sequenceLength).astype(defaultDType);

    m = SequentialContainer(
        _ConvolutionBlock(inputChannel, outputChannel1, kernelSize, 1),
        _ConvolutionBlock(outputChannel1, outputChannel2, kernelSize, 2),
        _ConvolutionBlock(outputChannel2, outputChannel3, kernelSize, 4),
    )
    Y, = m.forward(X);
    dX1, = m.backward(np.ones_like(Y));
    dX1N = numericGradient(lambda x: np.sum(m.forward(x)[0]), X);
    print(f"_ConvolutionBlock, numericGradient2 {getErrorText('dX error', dX1, dX1N)}");
    testModuleGradient(m, "_ConvolutionBlock, numericGradient2", X);
    print("\n");


def testEncoder1():
    batchSize, sequenceLength = 32, 24;
    intputSize, outputSize, hiddenSize, blockNum = 7, 8, 9, 2;
    X = np.random.randn(batchSize, sequenceLength, intputSize).astype(defaultDType);

    X1 = torch.tensor(X, dtype = torch.float32, requires_grad = False);
    encoder1 = TSEncoder(intputSize, outputSize, hiddenSize, depth = blockNum, dropout = 0.0);
    encoder1.train();
    np.random.seed(13);
    Y1 = encoder1(X1);
    torch.sum(Y1).backward();
    Y1 = Y1.detach().numpy();

    X2 = X;
    encoder2 = _Encoder(intputSize, outputSize, hiddenSize, blockNum = blockNum, representationDropout = 0.0);
    encoder2.context.isTrainingMode = True;
    injectTorchParams(encoder1, encoder2);
    np.random.seed(13);
    Y2, = encoder2.forward(X2);
    dX2, = encoder2.backward(np.ones_like(Y2));

    print(f"_Encoder, value1 {getErrorText('Y error', Y1, Y2)}");
    testTorchGradients(encoder1, encoder2);

    print("\n");


def testEncoderGradient1():
    batchSize, sequenceLength = 32, 24;
    intputSize, outputSize, hiddenSize, blockNum = 7, 8, 9, 2;
    X = np.random.randn(batchSize, sequenceLength, intputSize).astype(defaultDType);

    m = SequentialContainer(
        FunctionalNetModule("setSeed", lambda x: (np.random.seed(13), x)[1], lambda x, y, dy: dy),
        _Encoder(intputSize, outputSize, hiddenSize, blockNum = blockNum, representationDropout = 0.0),
    );
    m.context.isTrainingMode = True;

    Y, = m.forward(X);
    dX1, = m.backward(np.ones_like(Y));
    dX1N = numericGradient(lambda x: np.sum(m.forward(x)[0]), X);
    print(f"_Encoder, numericGradient1 {getErrorText('dX error', dX1, dX1N)}");
    testModuleGradient(m, "_Encoder, numericGradient1", X);
    print("\n");


def testTS2VecModel1():
    lr = 10.0;
    batchSize, sequenceLength = 32, 120;
    intputSize, outputSize, hiddenSize, blockNum = 7, 8, 9, 2;
    X = np.random.randn(batchSize, sequenceLength, intputSize).astype(defaultDType);

    m1 = TS2Vec(intputSize, outputSize, hiddenSize, depth = blockNum, device = "cpu", lr = lr, batch_size = batchSize);

    lossFunc = TS2VecLoss();
    optimizer = AveragedWeightNetOptimizer(SGD(lr = lr));
    m2 = TS2VecModel(intputSize, outputSize, hiddenSize, blockNum = blockNum, representationDropout = 0.0);
    m2.context.isTrainingMode = True;
    injectTorchParams(m1._net, m2);
    optimizer.updateStep(m2.params, m2.context);

    np.random.seed(1234);
    loss_log, z_log = m1.fit(X, n_epochs = 1, n_iters = 1, verbose = True);
    loss1 = loss_log[0];
    Z1, Z2 = z_log[0];

    np.random.seed(1234);
    Z1_, Z2_ = m2.forward(X);
    loss2 = lossFunc.forward(Z1_, Z2_);
    m2.clearGrads();
    m2.backward(*lossFunc.backward());
    optimizer.updateStep(m2.params, m2.context);

    print(f"TS2VecModel, value1, loss error: {abs(loss1 - loss2)} {getErrorText('Z1 error', Z1, Z1_)} {getErrorText('Z2 error', Z2, Z2_)}");

    print("\ntest gradients:");
    testTorchGradients(m1._net, m2);

    print("\ntest model params:");
    testTorchParams(m1._net, m2);

    print("\ntest averaged params:");
    testTorchTensors([p.data for p in m1.net.parameters()], [p.value for p in optimizer.shadowParams]);

    print("\n");


def testTS2VecModel2():
    batchSize, sequenceLength = 32, 120;
    intputSize, outputSize, hiddenSize, blockNum = 7, 8, 9, 2;
    X = np.random.randn(batchSize, sequenceLength, intputSize).astype(defaultDType);

    m1 = TS2Vec(intputSize, outputSize, hiddenSize, depth = blockNum, device = "cpu", batch_size = batchSize);

    m2 = TS2VecModel(intputSize, outputSize, hiddenSize, blockNum = blockNum, representationDropout = 0.0);
    m2.context.isTrainingMode = False;
    injectTorchParams(m1._net, m2);

    Y1 = m1.encode(X);
    Y2 = m2.encode(X);

    print(f"TS2VecModel, value2 {getErrorText('Y error', Y1, Y2)}");
    print("\n");


def testTS2VecModelGradient1():
    batchSize, sequenceLength = 32, 120;
    intputSize, outputSize, hiddenSize, blockNum = 7, 8, 9, 2;
    X = np.random.randn(batchSize, sequenceLength, intputSize).astype(defaultDType);

    m = SequentialContainer(
        FunctionalNetModule("setSeed", lambda x: (np.random.seed(1234), x)[1], lambda x, y, dy: dy),
        TS2VecModel(intputSize, outputSize, hiddenSize, blockNum = blockNum, latentDropout = 0.0, representationDropout = 0.0),
    );
    m.context.isTrainingMode = True;

    Z1, Z2, = m.forward(X);
    m.backward(np.ones_like(Z1), np.ones_like(Z2));
    testModuleGradient(m, "TS2VecModel, numericGradient1", X);
    print("\n");


def unitTest():
    print(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} start to unit test\n");

    # testTemporalContrastiveLoss1();
    # testTemporalContrastiveLossGradient1();
    # testTemporalContrastiveLossGradient2();
    # testInstanceContrastiveLoss1();
    # testContrastiveLossGradient1();
    # testContrastiveLossGradient2();
    # testContrastiveLossGradient3();
    # testTS2VecLossValue1(0.0);
    # testTS2VecLossValue1(0.5);
    # testTS2VecLossValue1(1.0);
    # testTS2VecLossValue1(0.0, minTemporalUnit = 2);
    # testTS2VecLossValue1(0.7, minTemporalUnit = 2);
    # testTS2VecLossValue1(1.0, minTemporalUnit = 2);
    # testTS2VecLossGradient1();

    # testConvolutionBlock1();
    # testConvolutionBlock2();
    # testConvolutionBlockGradient1();
    # testConvolutionBlockGradient2();
    # testEncoder1();
    # testEncoderGradient1();
    
    # testTS2VecModel1();
    # testTS2VecModel2();
    # testTS2VecModelGradient1();

    print(f"\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} end to unit test\n");


if __name__ == "__main__":
    unitTest();
